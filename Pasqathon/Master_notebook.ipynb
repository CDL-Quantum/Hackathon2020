{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have successfully authenticated to the platform!\n",
      "You have successfully authenticated to the platform!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import strawberryfields as sf\n",
    "from sklearn import svm\n",
    "from strawberryfields import ops\n",
    "from strawberryfields.decompositions import takagi\n",
    "from more_itertools import distinct_permutations\n",
    "from collections import Counter\n",
    "import os\n",
    "from functions import *\n",
    "sf.store_account('eUAjS1VasR1U1gW1pMSg5Bus3bEXWwA1jLge4QG3')\n",
    "sf.ping()\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating weighted graphs that fit the hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all weighted graphs can be encoded in the X8 hardware. We describe below a procedure to generate several kinds of weighted bipartite graphs that fit the hardware.\n",
    "\n",
    "Let's suppose that $B=UDU^{T}$ is a real symetric matrix with eigenvalues $\\{\\lambda_j\\}$.\n",
    "\n",
    "\n",
    "The eigenvalues of $A = \\begin{pmatrix}\n",
    "0 & B \\\\\n",
    "B & 0\n",
    "\\end{pmatrix}$ are $\\{\\lambda_j, -\\lambda_j\\}$, because $ Q^T A Q =\\begin{pmatrix}\n",
    "D & 0 \\\\\n",
    "0 & -D\n",
    "\\end{pmatrix}$, with $Q=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n",
    "U & -U \\\\\n",
    "U & U\n",
    "\\end{pmatrix}$. \n",
    "\n",
    "The singular values of a symmetric matrix are the absolute values of its eigenvalues (see corrollary C.5.2 of http://theanalysisofdata.com/probability/C_5.html#:~:text=If%20A%20is%20a%20symmetric,are%20square%20non%2Dsingular%20matrices.).\n",
    "\n",
    "The BipartiteGraphEmbed function compiled on the X8 hardware can compile matrices for which one has only one non-zero singular value (eventually repeated multiple times).\n",
    "\n",
    "From the construction above, that restricts the set $S=\\{\\lambda_j\\}$ to be $S=\\{0,d\\}$. One can still choose the multiplicity of the $d$ eigenvalue, and adapt the mean number of photons accordingly so that all Sgates have squeezing values $r=1$. \n",
    "\n",
    "Different \"kinds\" of graphs (with different labels) correspond to different number of non-zero singular values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graphs = 30\n",
    "graphs = [None]*3*num_graphs\n",
    "labels = [None]*3*num_graphs\n",
    "#Generate a set of common random unitaries for transforming the off-diagonal 4x4 block\n",
    "unitaries = generate_unitaries(num_graphs)\n",
    "\n",
    "#Generate 8x8 matrices that fit the hardware based on the unitaries\n",
    "for i in range(1,4): #Going through non-trivial singular values \n",
    "    for j in range(num_graphs):\n",
    "        labels[j+num_graphs*(i-1)] = i\n",
    "        graphs[j+num_graphs*(i-1)] = generate_matrices(i, unitaries[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark\n",
    "Let's note that the program also compiles successfully if one provides a more general matrix $B=UDV^T$ with $U$ and $V$ distinct unitaries. However, when sent to the hardware, the programm cannot be executed because of the absence of symmetry between operations applied on the top and on the bottom of the chip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating kernel (fingerprint) for each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fingerprinting function\n",
    "\n",
    "def fingerprint(samples, num_photons):\n",
    "    vector_basis = partition(num_photons)\n",
    "    empty_vector = orbitals(vector_basis)\n",
    "    clean_sample = truncate_samples(samples)\n",
    "    prob_dic = estimate_probs(clean_sample)\n",
    "    full_vector = vector_coordinates(prob_dic,empty_vector)\n",
    "    #print('full vector is:')\n",
    "    return full_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loichenriet/Pasqal_code/xanadu/env-xanadu/lib/python3.7/site-packages/strawberryfields/backends/gaussianbackend/backend.py:232: UserWarning: Cannot simulate non-Gaussian states. Conditional state after Fock measurement has not been updated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprints with all orbits up to num_photons created\n"
     ]
    }
   ],
   "source": [
    "#Created program for X8 chip\n",
    "simulator = True\n",
    "num_samples = 10\n",
    "num_photons = 6\n",
    "\n",
    "kernels = [None]*len(graphs)\n",
    "\n",
    "for i in range(len(graphs)):\n",
    "    # The mean photon number per mode m\n",
    "    # is set to ensure that the singular values\n",
    "    # are scaled such that all Sgates have squeezing value r=1\n",
    "    num_singular_values = i//num_graphs+1\n",
    "    A = graphs[i]\n",
    "    m = 0.345274461385554870545 * num_singular_values\n",
    "    \n",
    "    prog = sf.Program(8)\n",
    "    with prog.context as q:\n",
    "        ops.BipartiteGraphEmbed(A, mean_photon_per_mode=m) | q\n",
    "        ops.MeasureFock() | q\n",
    "\n",
    "    #prog.compile(\"X8\").print()\n",
    "    \n",
    "    if simulator:\n",
    "        eng = sf.Engine(\"gaussian\", backend_options={\"cutoff_dim\": 4})\n",
    "        job = eng.run(prog, shots=num_samples)\n",
    "        results=job # For simulator\n",
    "    else:\n",
    "        eng = sf.RemoteEngine(\"X8\")\n",
    "        job = eng.run(prog, shots=num_samples)\n",
    "\n",
    "        while job.status != \"complete\":\n",
    "            job.refresh()\n",
    "\n",
    "        results=job.result #for hardware\n",
    "    samples = results.samples\n",
    "    #here we calculate the figerprint instead of storing all outcomes:\n",
    "    kernels[i] = fingerprint(samples, num_photons)\n",
    "#print(kernels)\n",
    "print('Fingerprints with all orbits up to num_photons created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 1.0000000000000002\n",
      "Min: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "### check that probabilites sum to 1\n",
    "probs = []\n",
    "for j in range(len(graphs)):\n",
    "    full_proba = 0\n",
    "    for i in kernels[j].keys():\n",
    "        full_proba += kernels[j][i]\n",
    "    probs.append(full_proba)\n",
    "print('Max: '+str(np.max(probs)))\n",
    "print('Min: '+str(np.min(probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.625 0.    0.125 0.    0.    0.    0.    0.    0.    0.    0.    0.125\n",
      " 0.    0.    0.    0.    0.125 0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.   ]\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "#Converting into vectors\n",
    "vectorized_kernels = []\n",
    "for kernel in kernels:\n",
    "    vec_kernel = kernel_to_array(kernel)\n",
    "    vectorized_kernels.append(vec_kernel)\n",
    "vectorized_kernels = np.array(vectorized_kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning part. \n",
    "\n",
    "We generate a relatively large dataset, stored in the kernel_data file.\n",
    "\n",
    "As we can provide each datapoint with a label (the number of non-zero singular values), we'll first try supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_kernels = pickle.load( open( \"kernel_data\", \"rb\" ) )\n",
    "\n",
    "kernels_training = []\n",
    "kernels_testing = []\n",
    "labels_training = []\n",
    "labels_testing = []\n",
    "\n",
    "for m in range(150):\n",
    "    if m%3 == 0:\n",
    "        kernels_testing.append(vectorized_kernels[m])\n",
    "        labels_testing.append(m//50+1)\n",
    "    else:\n",
    "        kernels_training.append(vectorized_kernels[m])\n",
    "        labels_training.append(m//50+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(kernels_training, labels_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy 0.68\n"
     ]
    }
   ],
   "source": [
    "testing_data_accuracy = clf.predict(kernels_testing)\n",
    "average = 0.\n",
    "k = 0\n",
    "tot = 0\n",
    "for val in testing_data_accuracy:\n",
    "    if np.isclose(val, labels_testing[k]):\n",
    "        average += 1.\n",
    "        \n",
    "    k += 1\n",
    "    tot += 1\n",
    "average /= (50.)\n",
    "print(\"Classification accuracy\", average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a 68% accuracy in the classification of the graphs. Let's now try an unsepervised learning approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graphs = 150\n",
    "from sklearn.cluster import KMeans\n",
    "X = vectorized_kernels\n",
    "labels = [0]*num_graphs+[1]*num_graphs+[2]*num_graphs\n",
    "kmeans = KMeans(n_clusters=3).fit(X)\n",
    "fit = kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2733333333333333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_from_fit = fit.labels_\n",
    "correct = 0\n",
    "for i in range(len(labels_from_fit)):\n",
    "    print\n",
    "    if labels[i] == labels_from_fit[i]:\n",
    "        correct +=1\n",
    "correct = float(correct)/len(labels_from_fit)\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-xanadu",
   "language": "python",
   "name": "env-xanadu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
